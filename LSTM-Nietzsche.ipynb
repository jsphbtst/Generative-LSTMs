{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Generative LSTM on Nietzsche</h1>\n",
    "<h3>By Joseph J. Bautista</h3>\n",
    "<p>I ran this notebook in Paperspace by using their cloud-based GPU. Get started and get $10 freebie by clicking <a href=\"https://www.paperspace.com/&R=W949K8P\">here</a>. Here, a character-level LSTM model was trained on Nietzsche's writings. The model was only trained with 20 epochs. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import get_file\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temp=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temp\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "path = get_file(\"nietzsche.txt\", origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "text = open(path, encoding='utf-8').read().lower()\n",
    "print(\"Corpus length: {}\".format(len(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating sentence and next_chars arrays...\n",
      "Number of sequences: 200278\n",
      "Number of unique characters: 57\n",
      "Creating sentence and next_chars arrays...\n",
      "\n",
      "Vectorization...\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "maxlen = 60\n",
    "step = 3\n",
    "\n",
    "sentences = []\n",
    "next_chars = []\n",
    "print(\"Creating sentence and next_chars arrays...\")\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print(\"Number of sequences: {}\".format(len(sentences)))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print(\"Number of unique characters: {}\".format(len(chars)))\n",
    "print(\"Creating sentence and next_chars arrays...\\n\")\n",
    "\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)\n",
    "\n",
    "print(\"Vectorization...\")\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "print(\"Finished.\")\n",
    "\n",
    "# x.shape = (len(sentences), maxlen, len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateText(Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % 4 == 0:\n",
    "            generated_text = \"old scandinavian saga: it is thus rightly expressed from the\"\n",
    "            print(\"--- Generating with seed: '\" + generated_text + \"'\")\n",
    "            for i in range(400):\n",
    "                sampled = np.zeros((1, maxlen, len(chars)))\n",
    "                for t, char in enumerate(generated_text):\n",
    "                    sampled[0, t, char_indices[char]] = 1\n",
    "\n",
    "                preds = model.predict(sampled, verbose=0)[0]\n",
    "                next_index = sample(preds, 0.5)\n",
    "                next_char = chars[next_index]\n",
    "\n",
    "                sys.stdout.write(next_char)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "200278/200278 [==============================] - 123s 616us/step - loss: 2.0241\n",
      "--- Generating with seed: 'old scandinavian saga: it is thus rightly expressed from the'\n",
      " everimatien not deatidity and the more of the suth unding and the somed the callong that the samuth and but the store that that the sill of this store mand conjution and soult and the sall the evest and reance of the caltion of the sangher as of the mure and there far atting not the gore of\n",
      "contrenal and monality of the comalie. in most proust be the ract pichire couther the there hat singer bela\n",
      "Epoch 2/20\n",
      "200278/200278 [==============================] - 122s 610us/step - loss: 1.9234\n",
      "\n",
      "Epoch 3/20\n",
      "200278/200278 [==============================] - 123s 615us/step - loss: 1.8459\n",
      "\n",
      "Epoch 4/20\n",
      "200278/200278 [==============================] - 122s 611us/step - loss: 1.7841\n",
      "\n",
      "Epoch 5/20\n",
      "200278/200278 [==============================] - 123s 614us/step - loss: 1.7328\n",
      "--- Generating with seed: 'old scandinavian saga: it is thus rightly expressed from the'\n",
      " man a word in inteasty and may pass of the self, what the fact, and every intally and\n",
      "deente and destine and such a man extent and connection of the signest and\n",
      "sone the pristion of the strenct of the suppession of the reluge and sometters there of the self and even the sensed in the spirit of the most to present of the lay an any connece of the says and for the will the spirit of the mort of the\n",
      "Epoch 6/20\n",
      "200278/200278 [==============================] - 123s 616us/step - loss: 1.6906\n",
      "\n",
      "Epoch 7/20\n",
      "200278/200278 [==============================] - 124s 617us/step - loss: 1.6547\n",
      "\n",
      "Epoch 8/20\n",
      "200278/200278 [==============================] - 124s 618us/step - loss: 1.6246\n",
      "\n",
      "Epoch 9/20\n",
      "200278/200278 [==============================] - 123s 616us/step - loss: 1.5989\n",
      "--- Generating with seed: 'old scandinavian saga: it is thus rightly expressed from the'\n",
      " freedon philast, out of the sempleners and be net understiven with a gensure of the spirit and the man a souct to be morality of the religious souls the religions of the good moral to all the discions and his interdined to learn and in the still in a weal, all the encounter to the still in the sindling to be them the more and the spirit of seligious to the simples to the mankind to any seem: the \n",
      "Epoch 10/20\n",
      "200278/200278 [==============================] - 124s 618us/step - loss: 1.5753\n",
      "\n",
      "Epoch 11/20\n",
      "200278/200278 [==============================] - 123s 615us/step - loss: 1.5540\n",
      "\n",
      "Epoch 12/20\n",
      "200278/200278 [==============================] - 124s 617us/step - loss: 1.5356\n",
      "\n",
      "Epoch 13/20\n",
      "200278/200278 [==============================] - 122s 611us/step - loss: 1.5180\n",
      "--- Generating with seed: 'old scandinavian saga: it is thus rightly expressed from the'\n",
      " great string that it is rations and so \"in the lame the all that is that the super at all the ent and all the supersions of the self-enception, and are of the resemple to its a beardly the depties of the still rest to the more to may can for the have the same \"my and matter-its a for\n",
      "the last engrade is the strang the still be neture thre say the present the same religation of the masing that the\n",
      "Epoch 14/20\n",
      "200278/200278 [==============================] - 123s 613us/step - loss: 1.5016\n",
      "\n",
      "Epoch 15/20\n",
      "200278/200278 [==============================] - 122s 611us/step - loss: 1.4868\n",
      "\n",
      "Epoch 16/20\n",
      "200278/200278 [==============================] - 122s 609us/step - loss: 1.4736\n",
      "\n",
      "Epoch 17/20\n",
      "200278/200278 [==============================] - 124s 618us/step - loss: 1.4613\n",
      "--- Generating with seed: 'old scandinavian saga: it is thus rightly expressed from the'\n",
      "\n",
      "respective and the discovered to a perpain to the real and morality, himself the problem the same and part any condictive which he man acts and patistic and should lingually an accoust and as a so the\n",
      "entions and profound, the belition for the look and the much as a considerly and an account of the interman such a philosophical and sacrifice of the consequently and should in the period and all th\n",
      "Epoch 18/20\n",
      "200278/200278 [==============================] - 124s 617us/step - loss: 1.4485\n",
      "\n",
      "Epoch 19/20\n",
      "200278/200278 [==============================] - 123s 614us/step - loss: 1.4375\n",
      "\n",
      "Epoch 20/20\n",
      "200278/200278 [==============================] - 123s 613us/step - loss: 1.4272\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f25d817cda0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text = GenerateText()\n",
    "model.fit(x, y, batch_size=128, epochs=20, callbacks=[generate_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
